import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

MODEL_NAME = "distilgpt2"  # –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å —Å TF-–ø–æ–¥–¥–µ—Ä–∂–∫–æ–π

print("–ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = TFAutoModelForCausalLM.from_pretrained(MODEL_NAME)

# –ï—Å–ª–∏ —É —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –Ω–µ—Ç pad_token ‚Äî —Å–æ–∑–¥–∞–µ–º
if tokenizer.pad_token is None:
    tokenizer.add_special_tokens({'pad_token': '[PAD]'})
    model.resize_token_embeddings(len(tokenizer))

# –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞
chat_history_ids = None

def generate_reply(user_text: str,
                   max_new_tokens: int = 80,
                   temperature: float = 0.8,
                   top_p: float = 0.9,
                   top_k: int = 50) -> str:
    global chat_history_ids

    # –¢–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è + —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    new_input_ids = tokenizer.encode(
        f"User: {user_text}\nBot:",
        return_tensors="tf"
    )

    # –ü—Ä–∏–∫–ª–µ–∏–≤–∞–µ–º –∫ –∏—Å—Ç–æ—Ä–∏–∏
    if chat_history_ids is not None:
        input_ids = tf.concat([chat_history_ids, new_input_ids], axis=-1)
    else:
        input_ids = new_input_ids

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
    output_ids = model.generate(
        input_ids,
        max_new_tokens=max_new_tokens,
        pad_token_id=tokenizer.pad_token_id,
        do_sample=True,
        temperature=temperature,
        top_p=top_p,
        top_k=top_k,
        eos_token_id=tokenizer.eos_token_id
    )

    # –û–±–Ω–æ–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    chat_history_ids = output_ids

    # –î–æ—Å—Ç–∞—ë–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤–≤–æ–¥–∞
    generated_ids = output_ids[0][input_ids.shape[-1]:]
    bot_text = tokenizer.decode(generated_ids, skip_special_tokens=True)

    # –ù–µ–º–Ω–æ–≥–æ –ø–æ–¥—á–∏—Å—Ç–∏–º
    bot_text = bot_text.strip()

    # –ß–∞—Å—Ç–æ –º–æ–¥–µ–ª—å –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç "User:" ‚Äî –æ–±—Ä–µ–∂–µ–º –ø–æ —ç—Ç–æ–º—É –º–∞—Ä–∫–µ—Ä—É, –µ—Å–ª–∏ –ø–æ—è–≤–∏—Ç—Å—è
    stop_tokens = ["User:", "\nUser", "\nHuman:"]
    for stop in stop_tokens:
        idx = bot_text.find(stop)
        if idx != -1:
            bot_text = bot_text[:idx].strip()
            break

    return bot_text if bot_text else "–ù–µ —Å–æ–≤—Å–µ–º –ø–æ–Ω—è–ª, –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ üôÇ"

def main():
    print("–ß–∞—Ç-–±–æ—Ç –Ω–∞ TensorFlow –∑–∞–ø—É—â–µ–Ω.")
    print("–ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å. /exit –¥–ª—è –≤—ã—Ö–æ–¥–∞.")
    print("-" * 40)

    while True:
        user_text = input("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: ").strip()
        if user_text.lower() in ("/exit", "exit", "quit", "–≤—ã—Ö–æ–¥"):
            print("–ë–æ—Ç: –ë—ã–ª–æ –ø—Ä–∏—è—Ç–Ω–æ –ø–æ–æ–±—â–∞—Ç—å—Å—è! –ü–æ–∫–∞ üëã")
            break
        if not user_text:
            continue

        bot_reply = generate_reply(user_text)
        print(f"–ë–æ—Ç: {bot_reply}")
        print("-" * 40)

if __name__ == "__main__":
    main()
